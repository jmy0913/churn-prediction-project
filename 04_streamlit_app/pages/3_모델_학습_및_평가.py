import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import matplotlib
from matplotlib import font_manager as fm, rc

font_path = "C:/Windows/Fonts/malgun.ttf"
font_prop = fm.FontProperties(fname=font_path)
rc('font', family=font_prop.get_name())

plt.rc('axes', unicode_minus=False) # matplotlibì´ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìœ ë‹ˆì½”ë“œ ë§ˆì´ë„ˆìŠ¤ ë¹„í™œì„±í™”, ì•„ìŠ¤í‚¤ì½”ë“œ ë§ˆì´ë„ˆìŠ¤ ì‚¬ìš©)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from utils.preprocessing import preprocess_commerce_data, split_and_scale, preprocess_all_data, predict_churn1
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import confusion_matrix
import seaborn as sns

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler

# ëª¨ë¸ ê²½ë¡œ ë° threshold ì„¤ì •
model_options = {
    "XGBoost": ("../03_trained_model/xgboost_model(threshold=0.075).pkl", 0.075),
    "GradientBoosting": ("../03_trained_model/gb_model(threshold=0.1375).pkl", 0.1375),
    "RandomForest": ("../03_trained_model/random_forest_model(threshold=0.225).pkl", 0.225),
    "HistGradientBoosting": ("../03_trained_model/hgb_model(threshold=0.0001).pkl", 0.0001),
    "Stacking": ("../03_trained_model/stack_model(threshold=0.091).pkl", 0.091),
    "Voting": ("../03_trained_model/voting_model(threshold=0.1925).pkl", 0.137),
    "LGBM": ("../03_trained_model/lgbm(threshold=0.147).pkl", 0.147)
}

st.header("3. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€")

# í‰ê°€ ë°©ì‹ ì„ íƒ
view_mode = st.radio("ğŸ§ª í‰ê°€ ë°©ì‹ ì„ íƒ", ["ê°œë³„ ëª¨ë¸ ìƒì„¸ ë³´ê¸°", "ëª¨ë“  ëª¨ë¸ ë¹„êµ", "í´ëŸ¬ìŠ¤í„°ë§"], horizontal=True)

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
df_raw = pd.read_csv('data/CommerceData.csv')
df_processed = preprocess_commerce_data(df_raw)

exclude = ['CityTier', 'PreferredPaymentMode', 'Gender',
           'PreferedOrderCat', 'MaritalStatus', 'PreferredLoginDevice']

X_train, X_test, y_train, y_test, scaler = split_and_scale(
    df_processed, target_col='Churn', exclude_cols=exclude
)

if view_mode == "ê°œë³„ ëª¨ë¸ ìƒì„¸ ë³´ê¸°":
    selected_model = st.selectbox("ğŸ” í™•ì¸í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", list(model_options.keys()))
    model_path, threshold = model_options[selected_model]
    model = joblib.load(model_path)

    predict_mode = st.radio("ì˜ˆì¸¡ ë°©ì‹ ì„ íƒ", ["Threshold ì ìš©", "ê¸°ë³¸ ì˜ˆì¸¡"], horizontal=True)

    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X_test)[:, 1]
    else:
        y_proba = None  # í˜¹ì‹œë‚˜ ëŒ€ë¹„

    if predict_mode == "Threshold ì ìš©" and y_proba is not None:
        y_pred = (y_proba >= threshold).astype(int)
        st.info(f"ğŸ“Œ Threshold `{threshold}` ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        y_pred = model.predict(X_test)
        st.info("ğŸ“Œ ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤.")

    y_true = y_test

    acc = accuracy_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    report = classification_report(y_true, y_pred, output_dict=True)

    st.markdown(f"""
    - ì‚¬ìš© ëª¨ë¸: **{selected_model}**
    - í‰ê°€ ê¸°ì¤€(Testì…‹ ë°ì´í„°): Accuracy, Recall, Precision, F1 Score
    
    ğŸ“Œ **ì„±ëŠ¥ ê²°ê³¼**
    - Accuracy: `{acc:.4f}`  
    - Recall: `{rec:.4f}`  
    - Precision: `{prec:.4f}`  
    - F1 Score: `{f1:.4f}`
    """)

    metrics = {"Accuracy": acc, "Recall": rec, "Precision": prec, "F1 Score": f1}
    fig, ax = plt.subplots()
    ax.bar(metrics.keys(), metrics.values(), color=["skyblue", "salmon", "lightgreen", "violet"])
    ax.set_ylim(0, 1)
    ax.set_title(f"{selected_model} ì„±ëŠ¥ ì§€í‘œ - {predict_mode}")
    st.pyplot(fig)

    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    fig, ax = plt.subplots()
    ax.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
    ax.plot([0, 1], [0, 1], linestyle="--", color="gray")
    ax.set_title(f"{selected_model} ROC Curve")
    ax.set_xlabel("False Positive Rate")
    ax.set_ylabel("True Positive Rate")
    ax.legend()
    st.pyplot(fig)

    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_title("Confusion Matrix")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")
    st.pyplot(fig)

    st.subheader("ğŸ“‹ Classification Report")
    accuracy_val = report.pop("accuracy")
    report_df = pd.DataFrame(report).transpose().round(4)
    st.dataframe(report_df)
    st.markdown(f"âœ… **Overall Accuracy**: `{accuracy_val:.4f}`")

elif view_mode == "ëª¨ë“  ëª¨ë¸ ë¹„êµ":
    st.subheader("ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ê¸°ë³¸ vs Threshold)")

    compare_results = []

    for model_name, (path, threshold) in model_options.items():
        model = joblib.load(path)

        # Default predict()
        y_pred_default = model.predict(X_test)

        # Threshold predict_proba()
        if hasattr(model, "predict_proba"):
            y_proba = model.predict_proba(X_test)[:, 1]
            y_pred_thresh = (y_proba >= threshold).astype(int)
        else:
            y_pred_thresh = y_pred_default

        y_true = y_test

        for version, y_pred in zip(["Default", "Threshold"], [y_pred_default, y_pred_thresh]):
            report = classification_report(y_true, y_pred, output_dict=True)
            accuracy = report["accuracy"]
            pos_recall = report["1"]["recall"]

            compare_results.append({
                "Model": model_name,
                "Version": version,
                "Accuracy": accuracy,
                "Positive Recall": pos_recall
            })

    # ê²°ê³¼ í”„ë ˆì„ ë³€í™˜
    compare_df = pd.DataFrame(compare_results)

    # ìµœê³  ëª¨ë¸ ì°¾ê¸°
    best_row = compare_df[compare_df["Positive Recall"] == 1.0].sort_values(
        "Accuracy", ascending=False
    ).head(1)
    best_model_name = best_row["Model"].values[0]
    best_version = best_row["Version"].values[0]

    # "Best" ì»¬ëŸ¼ ì¶”ê°€
    compare_df["Best"] = compare_df.apply(
        lambda row: "â­ ìµœê³  ëª¨ë¸" if (row["Model"] == best_model_name and row["Version"] == best_version) else "", axis=1
    )

    # ì •ë ¬ (Positive Recall ê¸°ì¤€ â†’ Accuracy ê¸°ì¤€)
    compare_df = compare_df.sort_values(
        by=["Positive Recall", "Accuracy"], ascending=[False, False]
    ).reset_index(drop=True)

    # í‘œì‹œ
    st.dataframe(compare_df.round(4))

    # Positive Recall ì‹œê°í™” ì¶”ê°€
    fig, ax = plt.subplots(figsize=(10, 5))  # ê·¸ë˜í”„ë„ ì‚´ì§ ë„“í˜€ì¤Œ
    sns.barplot(data=compare_df, x="Model", y="Positive Recall", hue="Version", ax=ax)
    ax.set_title("ëª¨ë¸ë³„ Positive Recall ë¹„êµ")
    ax.set_ylim(0.85, 1.01)  # ë˜ëŠ” 0.9 ~ 1.0 êµ¬ê°„
    plt.xticks(rotation=30, ha='right')  # âœ… ë¼ë²¨ íšŒì „
    st.pyplot(fig)

    fig, ax = plt.subplots(figsize=(10, 5))  # ê·¸ë˜í”„ë„ ì‚´ì§ ë„“í˜€ì¤Œ
    sns.barplot(data=compare_df, x="Model", y="Accuracy", hue="Version", ax=ax, palette='Set2')
    ax.set_title("ëª¨ë¸ë³„ Accuracy ë¹„êµ")
    ax.set_ylim(0.85, 1.01)  # ë˜ëŠ” 0.9 ~ 1.0 êµ¬ê°„
    plt.xticks(rotation=30, ha='right')  # âœ… ë¼ë²¨ íšŒì „
    st.pyplot(fig)

elif view_mode == "í´ëŸ¬ìŠ¤í„°ë§":
    st.subheader("ğŸ“Š ê³ ê° êµ°ì§‘ ë¶„ì„ (KMeans)")

    from sklearn.cluster import KMeans
    from sklearn.metrics import silhouette_score
    from sklearn.preprocessing import StandardScaler

    # RFM ë°ì´í„° ì¤€ë¹„
    df_processed1 = preprocess_all_data(df_raw)
    rfm_df = df_processed1[['DaySinceLastOrder', 'OrderCount', 'CashbackAmount']].copy()
    rfm_df.columns = ['recency', 'frequency', 'monetary']

    scaler_rfm = joblib.load("../03_trained_model/kmeans_scaler.pkl")
    rfm_scaled = scaler_rfm.transform(rfm_df)

    # inertia & silhouette ê³„ì‚°
    inertias = []
    silhouettes = []
    k_range = range(2, 8)
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42)
        labels = kmeans.fit_predict(rfm_scaled)
        inertias.append(kmeans.inertia_)
        silhouettes.append(silhouette_score(rfm_scaled, labels))

    # ê·¸ë˜í”„ ì¶œë ¥
    fig, ax1 = plt.subplots(figsize=(8, 4))
    ax1.plot(k_range, inertias, marker='o', label='Inertia')
    ax1.set_ylabel('Inertia')
    ax1.set_xlabel('Number of clusters (k)')
    ax1.set_title('Elbow & Silhouette Score by k')

    ax2 = ax1.twinx()
    ax2.plot(k_range, silhouettes, marker='s', color='green', label='Silhouette Score')
    ax2.set_ylabel('Silhouette Score')

    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='center right')
    st.pyplot(fig)

    # k=6 ê¸°ì¤€ í´ëŸ¬ìŠ¤í„°ë§
    st.markdown("### âœ… ìµœì  êµ°ì§‘ ìˆ˜: k = 6")
    kmeans = joblib.load('../03_trained_model/kmeans.pkl')
    cluster_labels = kmeans.predict(rfm_scaled)
    rfm_df['cluster'] = cluster_labels

    # ì˜ˆì¸¡ í™•ë¥  ë¶™ì´ê¸° (ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°)
    from sklearn.ensemble import GradientBoostingClassifier

    df_labeled, df_scaled, df_result = predict_churn1(df_raw)
    rfm_df['model_pred_proba'] = df_result['Churn_Prob']

    # í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ìš”ì•½
    cluster_summary = rfm_df.groupby('cluster')[
        ['recency', 'frequency', 'monetary', 'model_pred_proba']].mean().round(4).reset_index()

    # íŠ¹ì„± ë° ì „ëµ ì„¤ëª… ì¶”ê°€
    descriptions = [
        ("ìµœê·¼ ë°©ë¬¸í–ˆì§€ë§Œ êµ¬ë§¤ ì ìŒ, ì´íƒˆ ìœ„í—˜ ë§¤ìš° ë†’ìŒ (ì´íƒˆë¥ : 0.2215)",
         "ì¦‰ê° ë¦¬í…ì…˜ ë§ˆì¼€íŒ…, í• ì¸ ì•Œë¦¼ í‘¸ì‹œ"),  # cluster 0

        ("ì˜¤ë˜ëœ ê³ ê°, í‰ê·  ì´í•˜ ì†Œë¹„, ê´€ê³„ ë‹¨ì ˆ ìœ„í—˜ (ì´íƒˆë¥ : 0.0912)",
         "ì¬ë°©ë¬¸ ìœ ë„, ë¦¬ë§ˆì¸ë“œ ë©”ì‹œì§€ ë°œì†¡"),  # cluster 1

        ("ìµœê·¼ ë°©ë¬¸ + ê³ ê°€ ì†Œë¹„, ë‹¨ë°œì„± ê°€ëŠ¥ì„± (ì´íƒˆë¥ : 0.1070)",
         "VIP í˜œíƒ ì œì•ˆ, ë‹¨ê¸° ê³ ê°€ ìƒí’ˆ ì¶”ì²œ"),  # cluster 2

        ("ìì£¼ êµ¬ë§¤ + ê³ ì§€ì¶œ, í•µì‹¬ ë¡œì—´ ê³ ê° (ì´íƒˆë¥ : 0.1199)",
         "í›„ê¸° ìš”ì²­, ë©¤ë²„ì‹­ ì œê³µ, ë¡œì—´í‹° ê°•í™”"),  # cluster 3

        ("ì˜¤ë˜ëì§€ë§Œ ê³ ì§€ì¶œ ìœ ì§€, ì¶©ì„± ê³ ê° (ì´íƒˆë¥ : 0.0632)",
         "í”„ë¦¬ë¯¸ì—„ í˜œíƒ ë¦¬ë§ˆì¸ë“œ, ê°ì‚¬ ë©”ì‹œì§€"),  # cluster 4

        ("ì¤‘ê°„ í™œë™, ì¤‘ê°„ ì†Œë¹„, ì´íƒˆ ì£¼ì˜ ê³ ê° (ì´íƒˆë¥ : 0.1683)",
         "ì´íƒˆ ë°©ì§€ ì¿ í°, ê°œì¸í™” ì½˜í…ì¸  ì œê³µ")  # cluster 5
    ]
    # í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ ê¸°ì¤€ ì •ë ¬ ë§ì¶”ê¸° ìœ„í•´ ì¸ë±ìŠ¤ ìˆœì„œë¡œ ë§¤í•‘
    cluster_summary['ê³ ê° íŠ¹ì„±'] = [descriptions[i][0] for i in cluster_summary['cluster']]
    cluster_summary['ì¶”ì²œ ì „ëµ'] = [descriptions[i][1] for i in cluster_summary['cluster']]

    # í´ëŸ¬ìŠ¤í„° ìš”ì•½ í‘œ ì¶œë ¥ (RFM + ì˜ˆì¸¡ í™•ë¥ ë§Œ)
    st.markdown("#### ğŸ“‹ í´ëŸ¬ìŠ¤í„°ë³„ RFM + ì´íƒˆ í™•ë¥  ìš”ì•½")
    rfm_summary_only = cluster_summary[['cluster', 'recency', 'frequency', 'monetary', 'model_pred_proba']]
    st.dataframe(rfm_summary_only)

    # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„±ê³¼ ì „ëµ ì¶œë ¥
    st.markdown("#### ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ê³ ê° íŠ¹ì„± ë° ì¶”ì²œ ì „ëµ")
    for i, row in cluster_summary.iterrows():
        st.markdown(f"""
        ğŸ”¹ **í´ëŸ¬ìŠ¤í„° {row['cluster']}**
        - **ê³ ê° íŠ¹ì„±**: {row['ê³ ê° íŠ¹ì„±']}
        - **ì¶”ì²œ ì „ëµ**: {row['ì¶”ì²œ ì „ëµ']}
        ---
        """)
